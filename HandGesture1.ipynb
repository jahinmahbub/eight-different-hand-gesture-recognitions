{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d052ef67",
   "metadata": {},
   "source": [
    "# Main Code - Hand Gesture Recognition Using OpenCV and MediaPipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45225525",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mzahi\\AppData\\Roaming\\Python\\Python311\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right hand: Thumb and middle finger gesture recognized\n",
      "Right hand: Thumb and middle finger gesture recognized\n",
      "Right hand: Thumb and ring finger gesture recognized\n",
      "Right hand: Thumb and middle finger gesture recognized\n",
      "Right hand: Thumb and middle finger gesture recognized\n",
      "Right hand: Thumb and middle finger gesture recognized\n",
      "Left hand: Thumb and middle finger gesture recognized\n",
      "Left hand: Thumb and middle finger gesture recognized\n",
      "Left hand: Thumb and middle finger gesture recognized\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "from math import hypot\n",
    "import numpy as np\n",
    "from comtypes import CLSCTX_ALL\n",
    "from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume\n",
    "import screen_brightness_control as sbc\n",
    "import os\n",
    "import vlc\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# Function to calculate Euclidean distance between two points\n",
    "def calculate_distance(point1, point2):\n",
    "    return hypot(point2[0] - point1[0], point2[1] - point1[1])\n",
    "\n",
    "class MediaPlayerThread(threading.Thread):\n",
    "    def __init__(self, file_paths):\n",
    "        super().__init__()\n",
    "        self.file_paths = file_paths\n",
    "        self.current_index = 0\n",
    "        self.player = vlc.MediaPlayer(self.file_paths[self.current_index])\n",
    "    \n",
    "    def play(self):\n",
    "        self.player.play()\n",
    "    \n",
    "    def pause(self):\n",
    "        self.player.pause()\n",
    "        \n",
    "    def stop(self):\n",
    "        self.player.stop()\n",
    "    \n",
    "    def next_song(self):\n",
    "        self.current_index = (self.current_index + 1) % len(self.file_paths)\n",
    "        self.player.stop()\n",
    "        self.player = vlc.MediaPlayer(self.file_paths[self.current_index])\n",
    "    \n",
    "    def previous_song(self):\n",
    "        self.current_index = (self.current_index - 1) % len(self.file_paths)\n",
    "        self.player.stop()\n",
    "        self.player = vlc.MediaPlayer(self.file_paths[self.current_index])\n",
    "    \n",
    "    def run(self):\n",
    "        self.play()\n",
    "        while True:\n",
    "            time.sleep(1)  # Adjust the sleep time as needed\n",
    "\n",
    "# Initialize the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize MediaPipe Hands module\n",
    "mpHands = mp.solutions.hands\n",
    "hands = mpHands.Hands(min_detection_confidence=0.75)\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize audio devices\n",
    "devices = AudioUtilities.GetSpeakers()\n",
    "interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n",
    "volume = interface.QueryInterface(IAudioEndpointVolume)\n",
    "\n",
    "# Get volume range\n",
    "volMin, volMax = volume.GetVolumeRange()[:2]\n",
    "\n",
    "# Flag to track if brightness changed\n",
    "brightness_changed = False\n",
    "\n",
    "# Initialize media player thread\n",
    "path = \"media/\"\n",
    "file_names = os.listdir(path)\n",
    "file_paths = [os.path.join(path, file) for file in file_names]\n",
    "media_player_thread = MediaPlayerThread(file_paths)\n",
    "media_player_thread.start()\n",
    "\n",
    "# Adding a short delay to allow the media player to initialize\n",
    "time.sleep(1)\n",
    "\n",
    "# Main loop to capture frames from webcam\n",
    "while True:\n",
    "    # Capture frame from webcam\n",
    "    success, img = cap.read()\n",
    "    \n",
    "    # Flip the frame horizontally for natural hand movements\n",
    "    img = cv2.flip(img, 1)\n",
    "    \n",
    "    # Convert frame to RGB format for processing by MediaPipe\n",
    "    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Process the frame to detect hands\n",
    "    results = hands.process(imgRGB)\n",
    "\n",
    "    # Lists to store landmark positions of left and right hands\n",
    "    left_lmList, right_lmList = [], []\n",
    "    \n",
    "    # Check if hands are detected and determine their labels (left or right)\n",
    "    if results.multi_hand_landmarks and results.multi_handedness:\n",
    "        for i in results.multi_handedness:\n",
    "            label = i.classification[0].label\n",
    "            if label == 'Left':\n",
    "                # Extract and store landmark positions for left hand\n",
    "                for lm in results.multi_hand_landmarks[0].landmark:\n",
    "                    h, w, _ = img.shape\n",
    "                    left_lmList.append([int(lm.x * w), int(lm.y * h)])\n",
    "                # Draw landmarks and connections for left hand\n",
    "                mpDraw.draw_landmarks(img, results.multi_hand_landmarks[0], mpHands.HAND_CONNECTIONS)\n",
    "            if label == 'Right':\n",
    "                # Extract and store landmark positions for right hand\n",
    "                index = 0\n",
    "                if len(results.multi_hand_landmarks) == 2:\n",
    "                    index = 1\n",
    "                for lm in results.multi_hand_landmarks[index].landmark:\n",
    "                    h, w, _ = img.shape\n",
    "                    right_lmList.append([int(lm.x * w), int(lm.y * h)])\n",
    "                    # Draw landmarks and connections for right hand\n",
    "                    mpDraw.draw_landmarks(img, results.multi_hand_landmarks[index], mpHands.HAND_CONNECTIONS)\n",
    "   \n",
    "    # Add a flag to indicate if a gesture is currently being processed\n",
    "    gesture_in_progress = False\n",
    "\n",
    "    # Control media playback based on hand gestures\n",
    "    if left_lmList != []:\n",
    "        x_thumb, y_thumb = left_lmList[4][0], left_lmList[4][1]\n",
    "        x_middle, y_middle = left_lmList[12][0], left_lmList[12][1]\n",
    "        x_ring, y_ring = left_lmList[16][0], left_lmList[16][1]\n",
    "        \n",
    "        distance_thumb_middle = calculate_distance((x_thumb, y_thumb), (x_middle, y_middle))\n",
    "        distance_thumb_ring = calculate_distance((x_thumb, y_thumb), (x_ring, y_ring))\n",
    "        # Left hand gestures\n",
    "        if not gesture_in_progress:\n",
    "            if distance_thumb_ring < 65:  # Thumb and ring finger gesture recognized for previous song\n",
    "                print(\"Left hand: Thumb and ring finger gesture recognized\")\n",
    "                media_player_thread.previous_song()\n",
    "                media_player_thread.play()\n",
    "                gesture_in_progress = True\n",
    "            elif distance_thumb_middle < 65:  # Thumb and middle finger gesture recognized for next song\n",
    "                print(\"Left hand: Thumb and middle finger gesture recognized\")\n",
    "                media_player_thread.next_song()\n",
    "                media_player_thread.play()\n",
    "                gesture_in_progress = True\n",
    "    if right_lmList != []:\n",
    "        x_thumb, y_thumb = right_lmList[4][0], right_lmList[4][1]\n",
    "        x_middle, y_middle = right_lmList[12][0], right_lmList[12][1]\n",
    "        x_ring, y_ring = right_lmList[16][0], right_lmList[16][1]\n",
    "        \n",
    "        distance_thumb_middle = calculate_distance((x_thumb, y_thumb), (x_middle, y_middle))\n",
    "        distance_thumb_ring = calculate_distance((x_thumb, y_thumb), (x_ring, y_ring))\n",
    "        # Right hand gestures\n",
    "        if not gesture_in_progress:\n",
    "            if distance_thumb_middle < 65:  # Thumb and middle finger gesture recognized for play/pause\n",
    "                print(\"Right hand: Thumb and middle finger gesture recognized\")\n",
    "                if media_player_thread.player.is_playing():\n",
    "                    media_player_thread.pause()\n",
    "                else:\n",
    "                    media_player_thread.play()\n",
    "                gesture_in_progress = True\n",
    "            elif distance_thumb_ring < 65:  # Thumb and ring finger gesture recognized for stop\n",
    "                print(\"Right hand: Thumb and ring finger gesture recognized\")\n",
    "                media_player_thread.stop()\n",
    "                gesture_in_progress = True\n",
    "\n",
    "    # Reset the flag after a short delay to allow for the next gesture\n",
    "    if gesture_in_progress:\n",
    "        time.sleep(2.5)  # Adjust the sleep time as needed\n",
    "        gesture_in_progress = False\n",
    "                \n",
    "    # Control screen brightness based on left hand gesture\n",
    "    if left_lmList != []:\n",
    "        x_thumb, y_thumb = left_lmList[4][0], left_lmList[4][1]\n",
    "        x_index, y_index = left_lmList[8][0], left_lmList[8][1]\n",
    "        x_middle, y_middle = left_lmList[12][0], left_lmList[12][1]\n",
    "        x_ring, y_ring = left_lmList[16][0], left_lmList[16][1]\n",
    "        x_pinky, y_pinky = left_lmList[20][0], left_lmList[20][1]\n",
    "\n",
    "        # Calculate distances between thumb and other fingers\n",
    "        distance_thumb_index = calculate_distance((x_thumb, y_thumb), (x_index, y_index))\n",
    "        distance_thumb_middle = calculate_distance((x_thumb, y_thumb), (x_middle, y_middle))\n",
    "        distance_thumb_ring = calculate_distance((x_thumb, y_thumb), (x_ring, y_ring))\n",
    "        distance_thumb_pinky = calculate_distance((x_thumb, y_thumb), (x_pinky, y_pinky))\n",
    "\n",
    "        # Control brightness based on thumb and finger gestures\n",
    "        if distance_thumb_index < 65:\n",
    "            brightness_levels = sbc.get_brightness()\n",
    "            brightness = brightness_levels[0] + 10\n",
    "            sbc.set_brightness(brightness)\n",
    "            brightness_changed = True\n",
    "        elif distance_thumb_pinky < 65:\n",
    "            brightness_levels = sbc.get_brightness()\n",
    "            brightness = brightness_levels[0] - 10\n",
    "            sbc.set_brightness(brightness)\n",
    "            brightness_changed = True\n",
    "\n",
    "    # Control volume based on right hand gesture\n",
    "    if right_lmList != []:\n",
    "        x_thumb, y_thumb = right_lmList[4][0], right_lmList[4][1]\n",
    "        x_index, y_index = right_lmList[8][0], right_lmList[8][1]\n",
    "        x_middle, y_middle = right_lmList[12][0], right_lmList[12][1]\n",
    "        x_ring, y_ring = right_lmList[16][0], right_lmList[16][1]\n",
    "        x_pinky, y_pinky = right_lmList[20][0], right_lmList[20][1]\n",
    "\n",
    "        # Calculate distances between thumb and other fingers\n",
    "        distance_thumb_index = calculate_distance((x_thumb, y_thumb), (x_index, y_index))\n",
    "        distance_thumb_middle = calculate_distance((x_thumb, y_thumb), (x_middle, y_middle))\n",
    "        distance_thumb_ring = calculate_distance((x_thumb, y_thumb), (x_ring, y_ring))\n",
    "        distance_thumb_pinky = calculate_distance((x_thumb, y_thumb), (x_pinky, y_pinky))\n",
    "\n",
    "        # Control volume based on thumb and finger gestures\n",
    "        if distance_thumb_index < 65:\n",
    "            current_vol = volume.GetMasterVolumeLevel()  # Get current volume level\n",
    "            new_vol = min(current_vol + 0.25, volMax)  # Increase volume by 10 dB, ensuring it does not exceed maximum\n",
    "            volume.SetMasterVolumeLevel(new_vol, None)\n",
    "        elif distance_thumb_pinky < 65:\n",
    "            current_vol = volume.GetMasterVolumeLevel()  # Get current volume level\n",
    "            new_vol = max(current_vol - 0.25, volMin)  # Decrease volume by 10 dB, ensuring it does not go below minimum\n",
    "            volume.SetMasterVolumeLevel(new_vol, None)\n",
    "            \n",
    "\n",
    "    # Display the annotated image\n",
    "    cv2.imshow('Image', img)\n",
    "    \n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "        media_player_thread.stop()\n",
    "        break\n",
    "\n",
    "    # Wait for brightness change to stabilize before continuing\n",
    "    if brightness_changed:\n",
    "        cv2.waitKey(500)\n",
    "        brightness_changed = False\n",
    "\n",
    "# Release resources and close windows\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd372566",
   "metadata": {},
   "source": [
    "# Previous Attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ad0ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "from math import hypot\n",
    "import numpy as np\n",
    "from comtypes import CLSCTX_ALL\n",
    "from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume\n",
    "import screen_brightness_control as sbc\n",
    "import os\n",
    "\n",
    "# Function to calculate Euclidean distance between two points\n",
    "def calculate_distance(point1, point2):\n",
    "    return hypot(point2[0] - point1[0], point2[1] - point1[1])\n",
    "\n",
    "# Initialize the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize MediaPipe Hands module\n",
    "mpHands = mp.solutions.hands\n",
    "hands = mpHands.Hands(min_detection_confidence=0.75)\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize audio devices\n",
    "devices = AudioUtilities.GetSpeakers()\n",
    "interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n",
    "volume = interface.QueryInterface(IAudioEndpointVolume)\n",
    "\n",
    "# Get volume range\n",
    "volMin, volMax = volume.GetVolumeRange()[:2]\n",
    "\n",
    "# Flag to track if brightness changed\n",
    "brightness_changed = False\n",
    "\n",
    "# Initialize media files\n",
    "# media_files = Files([\"Khaled - Alech Taadi.mp3\", \"Major Lazer - Que Calor (feat. J Balvin & El Alfa).mp3\",\"Heilung - In Maidjan.mp3\"])\n",
    "# file1 = File(\"Khaled - Alech Taadi.mp3\")\n",
    "# file2 = File(\"Major Lazer - Que Calor (feat. J Balvin & El Alfa).mp3\")\n",
    "# file3 = File(\"Heilung - In Maidjan.mp3\")\n",
    "\n",
    "# Main loop to capture frames from webcam\n",
    "while True:\n",
    "    # Capture frame from webcam\n",
    "    success, img = cap.read()\n",
    "    \n",
    "    # Flip the frame horizontally for natural hand movements\n",
    "    img = cv2.flip(img, 1)\n",
    "    \n",
    "    # Convert frame to RGB format for processing by MediaPipe\n",
    "    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Process the frame to detect hands\n",
    "    results = hands.process(imgRGB)\n",
    "\n",
    "    # Lists to store landmark positions of left and right hands\n",
    "    left_lmList, right_lmList = [], []\n",
    "    \n",
    "    # Check if hands are detected and determine their labels (left or right)\n",
    "    if results.multi_hand_landmarks and results.multi_handedness:\n",
    "        for i in results.multi_handedness:\n",
    "            label = i.classification[0].label\n",
    "            if label == 'Left':\n",
    "                # Extract and store landmark positions for left hand\n",
    "                for lm in results.multi_hand_landmarks[0].landmark:\n",
    "                    h, w, _ = img.shape\n",
    "                    left_lmList.append([int(lm.x * w), int(lm.y * h)])\n",
    "                # Draw landmarks and connections for left hand\n",
    "                mpDraw.draw_landmarks(img, results.multi_hand_landmarks[0], mpHands.HAND_CONNECTIONS)\n",
    "            if label == 'Right':\n",
    "                # Extract and store landmark positions for right hand\n",
    "                index = 0\n",
    "                if len(results.multi_hand_landmarks) == 2:\n",
    "                    index = 1\n",
    "                for lm in results.multi_hand_landmarks[index].landmark:\n",
    "                    h, w, _ = img.shape\n",
    "                    right_lmList.append([int(lm.x * w), int(lm.y * h)])\n",
    "                    # Draw landmarks and connections for right hand\n",
    "                    mpDraw.draw_landmarks(img, results.multi_hand_landmarks[index], mpHands.HAND_CONNECTIONS)\n",
    "\n",
    "    # Control screen brightness based on left hand gesture\n",
    "    if left_lmList != []:\n",
    "        x_thumb, y_thumb = left_lmList[4][0], left_lmList[4][1]\n",
    "        x_index, y_index = left_lmList[8][0], left_lmList[8][1]\n",
    "        x_middle, y_middle = left_lmList[12][0], left_lmList[12][1]\n",
    "        x_ring, y_ring = left_lmList[16][0], left_lmList[16][1]\n",
    "        x_pinky, y_pinky = left_lmList[20][0], left_lmList[20][1]\n",
    "\n",
    "        # Calculate distances between thumb and other fingers\n",
    "        distance_thumb_index = calculate_distance((x_thumb, y_thumb), (x_index, y_index))\n",
    "        distance_thumb_middle = calculate_distance((x_thumb, y_thumb), (x_middle, y_middle))\n",
    "        distance_thumb_ring = calculate_distance((x_thumb, y_thumb), (x_ring, y_ring))\n",
    "        distance_thumb_pinky = calculate_distance((x_thumb, y_thumb), (x_pinky, y_pinky))\n",
    "\n",
    "        # Control brightness based on thumb and finger gestures\n",
    "        if distance_thumb_index < 65:\n",
    "            brightness_levels = sbc.get_brightness()\n",
    "            brightness = brightness_levels[0] + 10\n",
    "            sbc.set_brightness(brightness)\n",
    "            brightness_changed = True\n",
    "        elif distance_thumb_pinky < 65:\n",
    "            brightness_levels = sbc.get_brightness()\n",
    "            brightness = brightness_levels[0] - 10\n",
    "            sbc.set_brightness(brightness)\n",
    "            brightness_changed = True\n",
    "\n",
    "\n",
    "    # Control volume based on right hand gesture\n",
    "    if right_lmList != []:\n",
    "        x_thumb, y_thumb = right_lmList[4][0], right_lmList[4][1]\n",
    "        x_index, y_index = right_lmList[8][0], right_lmList[8][1]\n",
    "        x_middle, y_middle = right_lmList[12][0], right_lmList[12][1]\n",
    "        x_ring, y_ring = right_lmList[16][0], right_lmList[16][1]\n",
    "        x_pinky, y_pinky = right_lmList[20][0], right_lmList[20][1]\n",
    "\n",
    "        # Calculate distances between thumb and other fingers\n",
    "        distance_thumb_index = calculate_distance((x_thumb, y_thumb), (x_index, y_index))\n",
    "        distance_thumb_middle = calculate_distance((x_thumb, y_thumb), (x_middle, y_middle))\n",
    "        distance_thumb_ring = calculate_distance((x_thumb, y_thumb), (x_ring, y_ring))\n",
    "        distance_thumb_pinky = calculate_distance((x_thumb, y_thumb), (x_pinky, y_pinky))\n",
    "\n",
    "        # Control volume based on thumb and finger gestures\n",
    "        if distance_thumb_index < 65:\n",
    "            current_vol = volume.GetMasterVolumeLevel()  # Get current volume level\n",
    "            new_vol = min(current_vol + 0.25, volMax)  # Increase volume by 10 dB, ensuring it does not exceed maximum\n",
    "            volume.SetMasterVolumeLevel(new_vol, None)\n",
    "        elif distance_thumb_pinky < 65:\n",
    "            current_vol = volume.GetMasterVolumeLevel()  # Get current volume level\n",
    "            new_vol = max(current_vol - 0.25, volMin)  # Decrease volume by 10 dB, ensuring it does not go below minimum\n",
    "            volume.SetMasterVolumeLevel(new_vol, None)\n",
    "\n",
    "    # Control media playback based on hand gestures\n",
    "    if len(left_lmList) >= 21 and len(right_lmList) >= 21:  # Ensure all landmarks are detected for both hands\n",
    "        # Left hand ring finger for previous\n",
    "        x_ring_left, y_ring_left = left_lmList[16][0], left_lmList[16][1]  # Ring finger landmark for left hand\n",
    "        if distance_thumb_ring_left < THRESHOLD:  # Adjust THRESHOLD according to your preference\n",
    "            print(\"Left hand: Thumb and ring finger gesture recognized\")\n",
    "            win32api.keybd_event(0xB1, 0, 0, 0)  # 0xB1 is the VK_MEDIA_PREV_TRACK key code\n",
    "\n",
    "        # Left hand middle finger for next\n",
    "        x_middle_left, y_middle_left = left_lmList[12][0], left_lmList[12][1]  # Middle finger landmark for left hand\n",
    "        if distance_thumb_middle_left < THRESHOLD:  # Adjust THRESHOLD according to your preference\n",
    "            print(\"Left hand: Thumb and middle finger gesture recognized\")\n",
    "            win32api.keybd_event(0xB0, 0, 0, 0)  # 0xB0 is the VK_MEDIA_NEXT_TRACK key code\n",
    "\n",
    "        # Right hand middle finger for play\n",
    "        x_middle_right, y_middle_right = right_lmList[12][0], right_lmList[12][1]  # Middle finger landmark for right hand\n",
    "        if distance_thumb_middle_right < THRESHOLD:  # Adjust THRESHOLD according to your preference\n",
    "            print(\"Right hand: Thumb and middle finger gesture recognized\")\n",
    "            win32api.keybd_event(0xB3, 0, 0, 0)  # 0xB3 is the VK_MEDIA_PLAY_PAUSE key code\n",
    "\n",
    "        # Right hand ring finger for pause\n",
    "        x_ring_right, y_ring_right = right_lmList[16][0], right_lmList[16][1]  # Ring finger landmark for right hand\n",
    "        if distance_thumb_ring_right < THRESHOLD:  # Adjust THRESHOLD according to your preference\n",
    "            print(\"Right hand: Thumb and ring finger gesture recognized\")\n",
    "            win32api.keybd_event(0xB3, 0, 0, 0)  # 0xB3 is the VK_MEDIA_PLAY_PAUSE key code\n",
    "\n",
    "    # Display the annotated image\n",
    "    cv2.imshow('Image', img)\n",
    "    \n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "        break\n",
    "\n",
    "    # Wait for brightness change to stabilize before continuing\n",
    "    if brightness_changed:\n",
    "        cv2.waitKey(500)\n",
    "        brightness_changed = False\n",
    "\n",
    "# Release resources and close windows\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b42b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "from math import hypot\n",
    "import numpy as np\n",
    "from comtypes import CLSCTX_ALL\n",
    "from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume\n",
    "import screen_brightness_control as sbc\n",
    "\n",
    "# Function to calculate Euclidean distance between two points\n",
    "def calculate_distance(point1, point2):\n",
    "    return hypot(point2[0] - point1[0], point2[1] - point1[1])\n",
    "\n",
    "# Initialize the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize MediaPipe Hands module\n",
    "mpHands = mp.solutions.hands\n",
    "hands = mpHands.Hands(min_detection_confidence=0.75)\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize audio devices\n",
    "devices = AudioUtilities.GetSpeakers()\n",
    "interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n",
    "volume = interface.QueryInterface(IAudioEndpointVolume)\n",
    "\n",
    "# Get volume range\n",
    "volMin, volMax = volume.GetVolumeRange()[:2]\n",
    "\n",
    "# Flag to track if brightness changed\n",
    "brightness_changed = False\n",
    "\n",
    "# Main loop to capture frames from webcam\n",
    "while True:\n",
    "    # Capture frame from webcam\n",
    "    success, img = cap.read()\n",
    "    \n",
    "    # Flip the frame horizontally for natural hand movements\n",
    "    img = cv2.flip(img, 1)\n",
    "    \n",
    "    # Convert frame to RGB format for processing by MediaPipe\n",
    "    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Process the frame to detect hands\n",
    "    results = hands.process(imgRGB)\n",
    "\n",
    "    # Lists to store landmark positions of left and right hands\n",
    "    left_lmList, right_lmList = [], []\n",
    "    \n",
    "    # Check if hands are detected and determine their labels (left or right)\n",
    "    if results.multi_hand_landmarks and results.multi_handedness:\n",
    "        for i in results.multi_handedness:\n",
    "            label = i.classification[0].label\n",
    "            if label == 'Left':\n",
    "                # Extract and store landmark positions for left hand\n",
    "                for lm in results.multi_hand_landmarks[0].landmark:\n",
    "                    h, w, _ = img.shape\n",
    "                    left_lmList.append([int(lm.x * w), int(lm.y * h)])\n",
    "                # Draw landmarks and connections for left hand\n",
    "                mpDraw.draw_landmarks(img, results.multi_hand_landmarks[0], mpHands.HAND_CONNECTIONS)\n",
    "            if label == 'Right':\n",
    "                # Extract and store landmark positions for right hand\n",
    "                index = 0\n",
    "                if len(results.multi_hand_landmarks) == 2:\n",
    "                    index = 1\n",
    "                for lm in results.multi_hand_landmarks[index].landmark:\n",
    "                    h, w, _ = img.shape\n",
    "                    right_lmList.append([int(lm.x * w), int(lm.y * h)])\n",
    "                    # Draw landmarks and connections for right hand\n",
    "                    mpDraw.draw_landmarks(img, results.multi_hand_landmarks[index], mpHands.HAND_CONNECTIONS)\n",
    "\n",
    "    # Control screen brightness based on left hand gesture\n",
    "    if left_lmList != []:\n",
    "        x1, y1 = left_lmList[4][0], left_lmList[4][1]\n",
    "        x2, y2 = left_lmList[8][0], left_lmList[8][1]\n",
    "\n",
    "        # Calculate length of line formed by thumb and index finger\n",
    "        length = hypot(x2 - x1, y2 - y1)\n",
    "\n",
    "        # Interpolate brightness based on length of line\n",
    "        bright = np.interp(length, [50, 200], [0, 100])\n",
    "        \n",
    "        # Check if there's a significant difference before changing brightness\n",
    "        if abs(bright - sbc.get_brightness()) > 5:\n",
    "            sbc.set_brightness(int(bright))\n",
    "            brightness_changed = True\n",
    "\n",
    "    # Control volume based on right hand gesture\n",
    "    if right_lmList != []:\n",
    "        x1, y1 = right_lmList[4][0], right_lmList[4][1]\n",
    "        x2, y2 = right_lmList[8][0], right_lmList[8][1]\n",
    "\n",
    "        # Calculate length of line formed by thumb and index finger\n",
    "        length = hypot(x2 - x1, y2 - y1)\n",
    "\n",
    "        # Interpolate volume based on length of line\n",
    "        vol = np.interp(length, [50, 200], [volMin, volMax])\n",
    "        volume.SetMasterVolumeLevel(vol, None)\n",
    "\n",
    "    # Recognize other finger combinations for left hand\n",
    "    if left_lmList != []:\n",
    "        # Extract x and y coordinates of each finger landmark\n",
    "        x_thumb, y_thumb = left_lmList[4][0], left_lmList[4][1]\n",
    "        x_index, y_index = left_lmList[8][0], left_lmList[8][1]\n",
    "        x_middle, y_middle = left_lmList[12][0], left_lmList[12][1]\n",
    "        x_ring, y_ring = left_lmList[16][0], left_lmList[16][1]\n",
    "        x_pinky, y_pinky = left_lmList[20][0], left_lmList[20][1]\n",
    "\n",
    "        # Calculate distances between thumb and other fingers\n",
    "        distance_thumb_index = calculate_distance((x_thumb, y_thumb), (x_index, y_index))\n",
    "        distance_thumb_middle = calculate_distance((x_thumb, y_thumb), (x_middle, y_middle))\n",
    "        distance_thumb_ring = calculate_distance((x_thumb, y_thumb), (x_ring, y_ring))\n",
    "        distance_thumb_pinky = calculate_distance((x_thumb, y_thumb), (x_pinky, y_pinky))\n",
    "\n",
    "        # Print recognized gestures without assigning actions\n",
    "        if distance_thumb_index < 65:\n",
    "            print(\"Left hand: Thumb and index finger gesture recognized\")\n",
    "        elif distance_thumb_middle < 65:\n",
    "            print(\"Left hand: Thumb and middle finger gesture recognized\")\n",
    "        elif distance_thumb_ring < 65:\n",
    "            print(\"Left hand: Thumb and ring finger gesture recognized\")\n",
    "        elif distance_thumb_pinky < 65:\n",
    "            print(\"Left hand: Thumb and pinky finger gesture recognized\")\n",
    "\n",
    "    # Recognize other finger combinations for right hand\n",
    "    if right_lmList != []:\n",
    "        # Extract x and y coordinates of each finger landmark\n",
    "        x_thumb, y_thumb = right_lmList[4][0], right_lmList[4][1]\n",
    "        x_index, y_index = right_lmList[8][0], right_lmList[8][1]\n",
    "        x_middle, y_middle = right_lmList[12][0], right_lmList[12][1]\n",
    "        x_ring, y_ring = right_lmList[16][0], right_lmList[16][1]\n",
    "        x_pinky, y_pinky = right_lmList[20][0], right_lmList[20][1]\n",
    "\n",
    "        # Calculate distances between thumb and other fingers\n",
    "        distance_thumb_index = calculate_distance((x_thumb, y_thumb), (x_index, y_index))\n",
    "        distance_thumb_middle = calculate_distance((x_thumb, y_thumb), (x_middle, y_middle))\n",
    "        distance_thumb_ring = calculate_distance((x_thumb, y_thumb), (x_ring, y_ring))\n",
    "        distance_thumb_pinky = calculate_distance((x_thumb, y_thumb), (x_pinky, y_pinky))\n",
    "\n",
    "        # Print recognized gestures without assigning actions\n",
    "        if distance_thumb_index < 65:\n",
    "            print(\"Right hand: Thumb and index finger gesture recognized\")\n",
    "        elif distance_thumb_middle < 65:\n",
    "            print(\"Right hand: Thumb and middle finger gesture recognized\")\n",
    "        elif distance_thumb_ring < 65:\n",
    "            print(\"Right hand: Thumb and ring finger gesture recognized\")\n",
    "        elif distance_thumb_pinky < 65:\n",
    "            print(\"Right hand: Thumb and pinky finger gesture recognized\")\n",
    "\n",
    "    # Display the annotated image\n",
    "    cv2.imshow('Image', img)\n",
    "    \n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "        break\n",
    "\n",
    "    # Wait for brightness change to stabilize before continuing\n",
    "    if brightness_changed:\n",
    "        cv2.waitKey(500)\n",
    "        brightness_changed = False\n",
    "\n",
    "# Release resources and close windows\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb81d0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "from math import hypot\n",
    "import numpy as np\n",
    "from comtypes import CLSCTX_ALL\n",
    "from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume\n",
    "import screen_brightness_control as sbc\n",
    "\n",
    "# Initialize the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize MediaPipe Hands module\n",
    "mpHands = mp.solutions.hands\n",
    "hands = mpHands.Hands(min_detection_confidence=0.75)\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize audio devices\n",
    "devices = AudioUtilities.GetSpeakers()\n",
    "interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n",
    "volume = interface.QueryInterface(IAudioEndpointVolume)\n",
    "\n",
    "# Get volume range\n",
    "volMin, volMax = volume.GetVolumeRange()[:2]\n",
    "\n",
    "# Flag to track if brightness changed\n",
    "brightness_changed = False\n",
    "\n",
    "# Main loop to capture frames from webcam\n",
    "while True:\n",
    "    # Capture frame from webcam\n",
    "    success, img = cap.read()\n",
    "    \n",
    "    # Flip the frame horizontally for natural hand movements\n",
    "    img = cv2.flip(img, 1)\n",
    "    \n",
    "    # Convert frame to RGB format for processing by MediaPipe\n",
    "    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Process the frame to detect hands\n",
    "    results = hands.process(imgRGB)\n",
    "\n",
    "    # Lists to store landmark positions of left and right hands\n",
    "    left_lmList, right_lmList = [], []\n",
    "    \n",
    "    # Check if hands are detected and determine their labels (left or right)\n",
    "    if results.multi_hand_landmarks and results.multi_handedness:\n",
    "        for i in results.multi_handedness:\n",
    "            label = i.classification[0].label\n",
    "            if label == 'Left':\n",
    "                # Extract and store landmark positions for left hand\n",
    "                for lm in results.multi_hand_landmarks[0].landmark:\n",
    "                    h, w, _ = img.shape\n",
    "                    left_lmList.append([int(lm.x * w), int(lm.y * h)])\n",
    "                # Draw landmarks and connections for left hand\n",
    "                mpDraw.draw_landmarks(img, results.multi_hand_landmarks[0], mpHands.HAND_CONNECTIONS)\n",
    "            if label == 'Right':\n",
    "                # Extract and store landmark positions for right hand\n",
    "                index = 0\n",
    "                if len(results.multi_hand_landmarks) == 2:\n",
    "                    index = 1\n",
    "                for lm in results.multi_hand_landmarks[index].landmark:\n",
    "                    h, w, _ = img.shape\n",
    "                    right_lmList.append([int(lm.x * w), int(lm.y * h)])\n",
    "                    # Draw landmarks and connections for right hand\n",
    "                    mpDraw.draw_landmarks(img, results.multi_hand_landmarks[index], mpHands.HAND_CONNECTIONS)\n",
    "\n",
    "    # Control screen brightness based on left hand gesture\n",
    "    if left_lmList != []:\n",
    "        x1, y1 = left_lmList[4][0], left_lmList[4][1]\n",
    "        x2, y2 = left_lmList[8][0], left_lmList[8][1]\n",
    "\n",
    "        # Calculate length of line formed by thumb and index finger\n",
    "        length = hypot(x2 - x1, y2 - y1)\n",
    "\n",
    "        # Interpolate brightness based on length of line\n",
    "        bright = np.interp(length, [50, 200], [0, 100])\n",
    "        \n",
    "        # Check if there's a significant difference before changing brightness\n",
    "        if abs(bright - sbc.get_brightness()) > 5:\n",
    "            sbc.set_brightness(int(bright))\n",
    "            brightness_changed = True\n",
    "\n",
    "    # Control volume based on right hand gesture\n",
    "    if right_lmList != []:\n",
    "        x1, y1 = right_lmList[4][0], right_lmList[4][1]\n",
    "        x2, y2 = right_lmList[8][0], right_lmList[8][1]\n",
    "\n",
    "        # Calculate length of line formed by thumb and index finger\n",
    "        length = hypot(x2 - x1, y2 - y1)\n",
    "\n",
    "        # Interpolate volume based on length of line\n",
    "        vol = np.interp(length, [50, 200], [volMin, volMax])\n",
    "        volume.SetMasterVolumeLevel(vol, None)\n",
    "\n",
    "    # Display the annotated image\n",
    "    cv2.imshow('Image', img)\n",
    "    \n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "        break\n",
    "\n",
    "    # Wait for brightness change to stabilize before continuing\n",
    "    if brightness_changed:\n",
    "        cv2.waitKey(500)\n",
    "        brightness_changed = False\n",
    "\n",
    "# Release resources and close windows\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dd53c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "from math import hypot\n",
    "import numpy as np\n",
    "\n",
    "# Function to calculate Euclidean distance between two points\n",
    "def calculate_distance(point1, point2):\n",
    "    return hypot(point2[0] - point1[0], point2[1] - point1[1])\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize MediaPipe Hands module\n",
    "mpHands = mp.solutions.hands\n",
    "hands = mpHands.Hands(min_detection_confidence=0.75)\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "\n",
    "# Threshold for finger distances\n",
    "THRESHOLD = 50\n",
    "\n",
    "# Main loop for capturing and processing frames\n",
    "while True:\n",
    "    # Capture frame from webcam\n",
    "    success, img = cap.read()\n",
    "    img = cv2.flip(img, 1)  # Flip horizontally for natural hand movements\n",
    "    \n",
    "    # Convert frame to RGB format for processing by MediaPipe\n",
    "    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Process the frame to detect hands\n",
    "    results = hands.process(imgRGB)\n",
    "\n",
    "    # List to store landmark positions of left hand\n",
    "    left_lmList = []\n",
    "\n",
    "    # Check if left hand landmarks are detected\n",
    "    if results.multi_hand_landmarks:\n",
    "        for handLandmarks in results.multi_hand_landmarks:\n",
    "            for lm in handLandmarks.landmark:\n",
    "                # Store landmark positions of left hand\n",
    "                h, w, _ = img.shape\n",
    "                left_lmList.append([int(lm.x * w), int(lm.y * h)])\n",
    "            # Draw landmarks and connections for left hand\n",
    "            mpDraw.draw_landmarks(img, handLandmarks, mpHands.HAND_CONNECTIONS)\n",
    "\n",
    "    # Recognize thumb and finger gestures in the left hand\n",
    "    if len(left_lmList) >= 21:  # Ensure all landmarks are detected\n",
    "        x_thumb, y_thumb = left_lmList[4][0], left_lmList[4][1]  # Thumb landmark\n",
    "        x_index, y_index = left_lmList[8][0], left_lmList[8][1]  # Index finger landmark\n",
    "        x_middle, y_middle = left_lmList[12][0], left_lmList[12][1]  # Middle finger landmark\n",
    "        x_ring, y_ring = left_lmList[16][0], left_lmList[16][1]  # Ring finger landmark\n",
    "        x_pinky, y_pinky = left_lmList[20][0], left_lmList[20][1]  # Pinky finger landmark\n",
    "\n",
    "        # Calculate distances between thumb and other fingers\n",
    "        distance_thumb_index = calculate_distance((x_thumb, y_thumb), (x_index, y_index))\n",
    "        distance_thumb_middle = calculate_distance((x_thumb, y_thumb), (x_middle, y_middle))\n",
    "        distance_thumb_ring = calculate_distance((x_thumb, y_thumb), (x_ring, y_ring))\n",
    "        distance_thumb_pinky = calculate_distance((x_thumb, y_thumb), (x_pinky, y_pinky))\n",
    "\n",
    "        # Define thresholds for distances to recognize different finger gestures\n",
    "        if distance_thumb_index < THRESHOLD:\n",
    "            print(\"Thumb and index finger gesture recognized\")\n",
    "        elif distance_thumb_middle < THRESHOLD:\n",
    "            print(\"Thumb and middle finger gesture recognized\")\n",
    "        elif distance_thumb_ring < THRESHOLD:\n",
    "            print(\"Thumb and ring finger gesture recognized\")\n",
    "        elif distance_thumb_pinky < THRESHOLD:\n",
    "            print(\"Thumb and pinky finger gesture recognized\")\n",
    "\n",
    "    # Display the annotated image\n",
    "    cv2.imshow('Hand Gesture Detection', img)\n",
    "    \n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources and close windows\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0313df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "from math import hypot\n",
    "import numpy as np\n",
    "\n",
    "# Function to calculate Euclidean distance between two points\n",
    "def calculate_distance(point1, point2):\n",
    "    return hypot(point2[0] - point1[0], point2[1] - point1[1])\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize MediaPipe Hands module\n",
    "mpHands = mp.solutions.hands\n",
    "hands = mpHands.Hands(min_detection_confidence=0.75, max_num_hands=2)  # Set max_num_hands to 2\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "\n",
    "# Threshold for finger distances\n",
    "THRESHOLD = 100\n",
    "\n",
    "# Main loop for capturing and processing frames\n",
    "while True:\n",
    "    # Capture frame from webcam\n",
    "    success, img = cap.read()\n",
    "    img = cv2.flip(img, 1)  # Flip horizontally for natural hand movements\n",
    "    \n",
    "    # Convert frame to RGB format for processing by MediaPipe\n",
    "    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Process the frame to detect hands\n",
    "    results = hands.process(imgRGB)\n",
    "\n",
    "    # Lists to store landmark positions of left and right hands\n",
    "    left_lmList = []\n",
    "    right_lmList = []\n",
    "\n",
    "    # Check if hand landmarks are detected\n",
    "    if results.multi_hand_landmarks:\n",
    "        for handLandmarks in results.multi_hand_landmarks:\n",
    "            # Extract hand landmarks and draw landmarks and connections\n",
    "            mpDraw.draw_landmarks(img, handLandmarks, mpHands.HAND_CONNECTIONS)\n",
    "\n",
    "            # Store landmark positions of left and right hands\n",
    "            for idx, lm in enumerate(handLandmarks.landmark):\n",
    "                h, w, _ = img.shape\n",
    "                cx, cy = int(lm.x * w), int(lm.y * h)  # Landmark coordinates\n",
    "                if idx == 0:  # Check landmark index to determine left or right hand\n",
    "                    left_lmList.append([cx, cy])\n",
    "                else:\n",
    "                    right_lmList.append([cx, cy])\n",
    "\n",
    "    # Recognize thumb and finger gestures for left hand\n",
    "    if len(left_lmList) >= 21:  # Ensure all landmarks are detected\n",
    "        x_thumb, y_thumb = left_lmList[4][0], left_lmList[4][1]  # Thumb landmark\n",
    "        x_index, y_index = left_lmList[8][0], left_lmList[8][1]  # Index finger landmark\n",
    "        x_middle, y_middle = left_lmList[12][0], left_lmList[12][1]  # Middle finger landmark\n",
    "        x_ring, y_ring = left_lmList[16][0], left_lmList[16][1]  # Ring finger landmark\n",
    "        x_pinky, y_pinky = left_lmList[20][0], left_lmList[20][1]  # Pinky finger landmark\n",
    "\n",
    "        # Calculate distances between thumb and other fingers\n",
    "        distance_thumb_index = calculate_distance((x_thumb, y_thumb), (x_index, y_index))\n",
    "        distance_thumb_middle = calculate_distance((x_thumb, y_thumb), (x_middle, y_middle))\n",
    "        distance_thumb_ring = calculate_distance((x_thumb, y_thumb), (x_ring, y_ring))\n",
    "        distance_thumb_pinky = calculate_distance((x_thumb, y_thumb), (x_pinky, y_pinky))\n",
    "\n",
    "        # Define thresholds for distances to recognize different finger gestures\n",
    "        if distance_thumb_index < THRESHOLD:\n",
    "            print(\"Left hand: Thumb and index finger gesture recognized\")\n",
    "        elif distance_thumb_middle < THRESHOLD:\n",
    "            print(\"Left hand: Thumb and middle finger gesture recognized\")\n",
    "        elif distance_thumb_ring < THRESHOLD:\n",
    "            print(\"Left hand: Thumb and ring finger gesture recognized\")\n",
    "        elif distance_thumb_pinky < THRESHOLD:\n",
    "            print(\"Left hand: Thumb and pinky finger gesture recognized\")\n",
    "\n",
    "    # Recognize thumb and finger gestures for right hand\n",
    "    if len(right_lmList) >= 21:  # Ensure all landmarks are detected\n",
    "        x_thumb, y_thumb = right_lmList[4][0], right_lmList[4][1]  # Thumb landmark\n",
    "        x_index, y_index = right_lmList[8][0], right_lmList[8][1]  # Index finger landmark\n",
    "        x_middle, y_middle = right_lmList[12][0], right_lmList[12][1]  # Middle finger landmark\n",
    "        x_ring, y_ring = right_lmList[16][0], right_lmList[16][1]  # Ring finger landmark\n",
    "        x_pinky, y_pinky = right_lmList[20][0], right_lmList[20][1]  # Pinky finger landmark\n",
    "\n",
    "        # Calculate distances between thumb and other fingers\n",
    "        distance_thumb_index = calculate_distance((x_thumb, y_thumb), (x_index, y_index))\n",
    "        distance_thumb_middle = calculate_distance((x_thumb, y_thumb), (x_middle, y_middle))\n",
    "        distance_thumb_ring = calculate_distance((x_thumb, y_thumb), (x_ring, y_ring))\n",
    "        distance_thumb_pinky = calculate_distance((x_thumb, y_thumb), (x_pinky, y_pinky))\n",
    "\n",
    "        # Define thresholds for distances to recognize different finger gestures\n",
    "        if distance_thumb_index < THRESHOLD:\n",
    "            print(\"Right hand: Thumb and index finger gesture recognized\")\n",
    "        elif distance_thumb_middle < THRESHOLD:\n",
    "            print(\"Right hand: Thumb and middle finger gesture recognized\")\n",
    "        elif distance_thumb_ring < THRESHOLD:\n",
    "            print(\"Right hand: Thumb and ring finger gesture recognized\")\n",
    "        elif distance_thumb_pinky < THRESHOLD:\n",
    "            print(\"Right hand: Thumb and pinky finger gesture recognized\")\n",
    "\n",
    "    # Display the annotated image\n",
    "    cv2.imshow('Hand Gesture Detection', img)\n",
    "    \n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources and close windows\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd5f1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "from math import hypot\n",
    "import numpy as np\n",
    "\n",
    "# Function to calculate Euclidean distance between two points\n",
    "def calculate_distance(point1, point2):\n",
    "    return hypot(point2[0] - point1[0], point2[1] - point1[1])\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize MediaPipe Hands module\n",
    "mpHands = mp.solutions.hands\n",
    "hands = mpHands.Hands(min_detection_confidence=0.75, max_num_hands=2)  # Set max_num_hands to 2\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "\n",
    "# Threshold for finger distances\n",
    "THRESHOLD = 65  # Adjust this threshold value\n",
    "\n",
    "# Main loop for capturing and processing frames\n",
    "while True:\n",
    "    # Capture frame from webcam\n",
    "    success, img = cap.read()\n",
    "    img = cv2.flip(img, 1)  # Flip horizontally for natural hand movements\n",
    "    \n",
    "    # Convert frame to RGB format for processing by MediaPipe\n",
    "    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Process the frame to detect hands\n",
    "    results = hands.process(imgRGB)\n",
    "\n",
    "    # Lists to store landmark positions of left and right hands\n",
    "    left_lmList = []\n",
    "    right_lmList = []\n",
    "\n",
    "    # Check if hand landmarks are detected\n",
    "    if results.multi_hand_landmarks:\n",
    "        for handLandmarks in results.multi_hand_landmarks:\n",
    "            # Extract hand landmarks and draw landmarks and connections\n",
    "            mpDraw.draw_landmarks(img, handLandmarks, mpHands.HAND_CONNECTIONS)\n",
    "\n",
    "            # Store landmark positions of left and right hands\n",
    "            for idx, lm in enumerate(handLandmarks.landmark):\n",
    "                h, w, _ = img.shape\n",
    "                cx, cy = int(lm.x * w), int(lm.y * h)  # Landmark coordinates\n",
    "                if cx < w // 2:  # Check if landmark is on the left or right side of the frame\n",
    "                    left_lmList.append([cx, cy])\n",
    "                else:\n",
    "                    right_lmList.append([cx, cy])\n",
    "\n",
    "    # Recognize thumb and finger gestures for left hand\n",
    "    if len(left_lmList) >= 21:  # Ensure all landmarks are detected for left hand\n",
    "        x_thumb, y_thumb = left_lmList[4][0], left_lmList[4][1]  # Thumb landmark\n",
    "        x_index, y_index = left_lmList[8][0], left_lmList[8][1]  # Index finger landmark\n",
    "        x_middle, y_middle = left_lmList[12][0], left_lmList[12][1]  # Middle finger landmark\n",
    "        x_ring, y_ring = left_lmList[16][0], left_lmList[16][1]  # Ring finger landmark\n",
    "        x_pinky, y_pinky = left_lmList[20][0], left_lmList[20][1]  # Pinky finger landmark\n",
    "\n",
    "        # Calculate distances between thumb and other fingers\n",
    "        distance_thumb_index = calculate_distance((x_thumb, y_thumb), (x_index, y_index))\n",
    "        distance_thumb_middle = calculate_distance((x_thumb, y_thumb), (x_middle, y_middle))\n",
    "        distance_thumb_ring = calculate_distance((x_thumb, y_thumb), (x_ring, y_ring))\n",
    "        distance_thumb_pinky = calculate_distance((x_thumb, y_thumb), (x_pinky, y_pinky))\n",
    "\n",
    "        # Define thresholds for distances to recognize different finger gestures\n",
    "        if distance_thumb_index < THRESHOLD:\n",
    "            print(\"Left hand: Thumb and index finger gesture recognized\")\n",
    "        elif distance_thumb_middle < THRESHOLD:\n",
    "            print(\"Left hand: Thumb and middle finger gesture recognized\")\n",
    "        elif distance_thumb_ring < THRESHOLD:\n",
    "            print(\"Left hand: Thumb and ring finger gesture recognized\")\n",
    "        elif distance_thumb_pinky < THRESHOLD:\n",
    "            print(\"Left hand: Thumb and pinky finger gesture recognized\")\n",
    "\n",
    "    # Recognize thumb and finger gestures for right hand\n",
    "    if len(right_lmList) >= 21:  # Ensure all landmarks are detected for right hand\n",
    "        x_thumb, y_thumb = right_lmList[4][0], right_lmList[4][1]  # Thumb landmark\n",
    "        x_index, y_index = right_lmList[8][0], right_lmList[8][1]  # Index finger landmark\n",
    "        x_middle, y_middle = right_lmList[12][0], right_lmList[12][1]  # Middle finger landmark\n",
    "        x_ring, y_ring = right_lmList[16][0], right_lmList[16][1]  # Ring finger landmark\n",
    "        x_pinky, y_pinky = right_lmList[20][0], right_lmList[20][1]  # Pinky finger landmark\n",
    "\n",
    "        # Calculate distances between thumb and other fingers\n",
    "        distance_thumb_index = calculate_distance((x_thumb, y_thumb), (x_index, y_index))\n",
    "        distance_thumb_middle = calculate_distance((x_thumb, y_thumb), (x_middle, y_middle))\n",
    "        distance_thumb_ring = calculate_distance((x_thumb, y_thumb), (x_ring, y_ring))\n",
    "        distance_thumb_pinky = calculate_distance((x_thumb, y_thumb), (x_pinky, y_pinky))\n",
    "\n",
    "        # Define thresholds for distances to recognize different finger gestures\n",
    "        if distance_thumb_index < THRESHOLD:\n",
    "            print(\"Right hand: Thumb and index finger gesture recognized\")\n",
    "        elif distance_thumb_middle < THRESHOLD:\n",
    "            print(\"Right hand: Thumb and middle finger gesture recognized\")\n",
    "        elif distance_thumb_ring < THRESHOLD:\n",
    "            print(\"Right hand: Thumb and ring finger gesture recognized\")\n",
    "        elif distance_thumb_pinky < THRESHOLD:\n",
    "            print(\"Right hand: Thumb and pinky finger gesture recognized\")\n",
    "\n",
    "    # Display the annotated image\n",
    "    cv2.imshow('Hand Gesture Detection', img)\n",
    "    \n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources and close windows\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d352386c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "from math import hypot\n",
    "import numpy as np\n",
    "\n",
    "# Function to calculate Euclidean distance between two points\n",
    "def calculate_distance(point1, point2):\n",
    "    return hypot(point2[0] - point1[0], point2[1] - point1[1])\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize MediaPipe Hands module\n",
    "mpHands = mp.solutions.hands\n",
    "hands = mpHands.Hands(min_detection_confidence=0.75)\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "\n",
    "# Threshold for thumb and middle finger distance\n",
    "THRESHOLD = 50\n",
    "\n",
    "# Main loop for capturing and processing frames\n",
    "while True:\n",
    "    # Capture frame from webcam\n",
    "    success, img = cap.read()\n",
    "    img = cv2.flip(img, 1)  # Flip horizontally for natural hand movements\n",
    "    \n",
    "    # Convert frame to RGB format for processing by MediaPipe\n",
    "    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Process the frame to detect hands\n",
    "    results = hands.process(imgRGB)\n",
    "\n",
    "    # List to store landmark positions of left hand\n",
    "    left_lmList = []\n",
    "\n",
    "    # Check if left hand landmarks are detected\n",
    "    if results.multi_hand_landmarks:\n",
    "        for handLandmarks in results.multi_hand_landmarks:\n",
    "            for lm in handLandmarks.landmark:\n",
    "                # Store landmark positions of left hand\n",
    "                h, w, _ = img.shape\n",
    "                left_lmList.append([int(lm.x * w), int(lm.y * h)])\n",
    "            # Draw landmarks and connections for left hand\n",
    "            mpDraw.draw_landmarks(img, handLandmarks, mpHands.HAND_CONNECTIONS)\n",
    "\n",
    "    # Recognize thumb and middle finger gesture in the left hand\n",
    "    if len(left_lmList) >= 9:  # Ensure all landmarks are detected\n",
    "        x_thumb, y_thumb = left_lmList[4][0], left_lmList[4][1]  # Thumb landmark\n",
    "        x_index, y_index = left_lmList[8][0], left_lmList[8][1]  # Index finger landmark\n",
    "\n",
    "        # Calculate Euclidean distance between thumb and index finger landmarks\n",
    "        distance_thumb_index = calculate_distance((x_thumb, y_thumb), (x_index, y_index))\n",
    "\n",
    "        # If the distance is below the threshold, recognize the gesture\n",
    "        if distance_thumb_index < THRESHOLD:\n",
    "            print(\"Thumb and index finger gesture recognized\")\n",
    "\n",
    "    # Display the annotated image\n",
    "    cv2.imshow('Hand Gesture Detection', img)\n",
    "    \n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources and close windows\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72b06f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "from math import hypot\n",
    "\n",
    "# Function to calculate Euclidean distance between two points\n",
    "def calculate_distance(point1, point2):\n",
    "    return hypot(point2[0] - point1[0], point2[1] - point1[1])\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize MediaPipe Hands module\n",
    "mpHands = mp.solutions.hands\n",
    "hands = mpHands.Hands(min_detection_confidence=0.75, max_num_hands=2)  # Set max_num_hands to 2\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "\n",
    "# Threshold for finger distances\n",
    "THRESHOLD = 50\n",
    "\n",
    "# Main loop for capturing and processing frames\n",
    "while True:\n",
    "    # Capture frame from webcam\n",
    "    success, img = cap.read()\n",
    "    img = cv2.flip(img, 1)  # Flip horizontally for natural hand movements\n",
    "    \n",
    "    # Convert frame to RGB format for processing by MediaPipe\n",
    "    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Process the frame to detect hands\n",
    "    results = hands.process(imgRGB)\n",
    "\n",
    "    # Lists to store landmark positions of left and right hands\n",
    "    left_lmList = []\n",
    "    right_lmList = []\n",
    "\n",
    "    # Check if hand landmarks are detected\n",
    "    if results.multi_hand_landmarks:\n",
    "        for handLandmarks in results.multi_hand_landmarks:\n",
    "            # Extract hand landmarks and draw landmarks and connections\n",
    "            mpDraw.draw_landmarks(img, handLandmarks, mpHands.HAND_CONNECTIONS)\n",
    "\n",
    "            # Store landmark positions of left and right hands\n",
    "            for idx, lm in enumerate(handLandmarks.landmark):\n",
    "                h, w, _ = img.shape\n",
    "                cx, cy = int(lm.x * w), int(lm.y * h)  # Landmark coordinates\n",
    "                if cx < w // 2:  # Check if landmark is on the left or right side of the frame\n",
    "                    left_lmList.append([cx, cy])\n",
    "                else:\n",
    "                    right_lmList.append([cx, cy])\n",
    "\n",
    "    # Recognize thumb and finger gestures for left hand\n",
    "    if len(left_lmList) >= 21:  # Ensure all landmarks are detected for left hand\n",
    "        x_thumb, y_thumb = left_lmList[4][0], left_lmList[4][1]  # Thumb landmark\n",
    "        x_index, y_index = left_lmList[8][0], left_lmList[8][1]  # Index finger landmark\n",
    "\n",
    "        # Calculate Euclidean distance between thumb and index finger landmarks\n",
    "        distance_thumb_index = calculate_distance((x_thumb, y_thumb), (x_index, y_index))\n",
    "\n",
    "        # If the distance is below the threshold, recognize the gesture\n",
    "        if distance_thumb_index < THRESHOLD:\n",
    "            print(\"Left hand: Thumb and index finger gesture recognized\")\n",
    "\n",
    "    # Recognize thumb and finger gestures for right hand\n",
    "    if len(right_lmList) >= 21:  # Ensure all landmarks are detected for right hand\n",
    "        x_thumb, y_thumb = right_lmList[4][0], right_lmList[4][1]  # Thumb landmark\n",
    "        x_index, y_index = right_lmList[8][0], right_lmList[8][1]  # Index finger landmark\n",
    "\n",
    "        # Calculate Euclidean distance between thumb and index finger landmarks\n",
    "        distance_thumb_index = calculate_distance((x_thumb, y_thumb), (x_index, y_index))\n",
    "\n",
    "        # If the distance is below the threshold, recognize the gesture\n",
    "        if distance_thumb_index < THRESHOLD:\n",
    "            print(\"Right hand: Thumb and index finger gesture recognized\")\n",
    "\n",
    "    # Display the annotated image\n",
    "    cv2.imshow('Hand Gesture Detection', img)\n",
    "    \n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources and close windows\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e326d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vlc \n",
    "import os\n",
    "import time\n",
    "path = \"media/\"\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13987909",
   "metadata": {},
   "outputs": [],
   "source": [
    "L=os.listdir(path)\n",
    "song = vlc.MediaPlayer(L[0])\n",
    "song.play()\n",
    "print('is_playing:', song.is_playing())  # 0 = False\n",
    "\n",
    "time.sleep(5)  # sleep because it needs time to start playing\n",
    "\n",
    "print('is_playing:', song.is_playing())  # 1 = True\n",
    "\n",
    "while song.is_playing():\n",
    "    time.sleep(5)  # sleep to use less CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd6dd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vlc \n",
    "import os\n",
    "import time\n",
    "import threading\n",
    "\n",
    "path = \"media/\"\n",
    "os.listdir(path)\n",
    "\n",
    "class MediaPlayerThread(threading.Thread):\n",
    "    def __init__(self, file_path):\n",
    "        super().__init__()\n",
    "        self.song = vlc.MediaPlayer(file_path)\n",
    "    \n",
    "    def run(self):\n",
    "        self.song.play()\n",
    "        while True:\n",
    "            time.sleep(1)\n",
    "\n",
    "L = os.listdir(path)\n",
    "media_player_thread = MediaPlayerThread(os.path.join(path, L[0]))\n",
    "media_player_thread.start()\n",
    "\n",
    "# Adding a short delay to allow the media player to initialize\n",
    "time.sleep(1)\n",
    "\n",
    "print('is_playing:', media_player_thread.song.is_playing())\n",
    "\n",
    "# Now you can pause the song from another cell\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c77730",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_player_thread.song.pause()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa104f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_player_thread.song.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e92ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_player_thread.song.pause()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62ffd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_player_thread.song.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169ec439",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_player_thread.song.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2010163e",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_player_thread.song.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf4d7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_player_thread.song.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a989a575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vlc \n",
    "import os\n",
    "import time\n",
    "import threading\n",
    "\n",
    "class MediaPlayerThread(threading.Thread):\n",
    "    def __init__(self, file_paths):\n",
    "        super().__init__()\n",
    "        self.file_paths = file_paths\n",
    "        self.current_index = 0\n",
    "        self.player = vlc.MediaPlayer(self.file_paths[self.current_index])\n",
    "    \n",
    "    def play(self):\n",
    "        self.player.play()\n",
    "    \n",
    "    def pause(self):\n",
    "        self.player.pause()\n",
    "        \n",
    "    def stop(self):\n",
    "        self.player.stop()\n",
    "    \n",
    "    def next_song(self):\n",
    "        self.current_index = (self.current_index + 1) % len(self.file_paths)\n",
    "        self.player.stop()\n",
    "        self.player = vlc.MediaPlayer(self.file_paths[self.current_index])\n",
    "        self.player.play()\n",
    "    \n",
    "    def previous_song(self):\n",
    "        self.current_index = (self.current_index - 1) % len(self.file_paths)\n",
    "        self.player.stop()\n",
    "        self.player = vlc.MediaPlayer(self.file_paths[self.current_index])\n",
    "        self.player.play()\n",
    "    \n",
    "    def run(self):\n",
    "        self.play()\n",
    "        while True:\n",
    "            time.sleep(1)  # Adjust the sleep time as needed\n",
    "\n",
    "path = \"media/\"\n",
    "file_names = os.listdir(path)\n",
    "file_paths = [os.path.join(path, file) for file in file_names]\n",
    "\n",
    "media_player_thread = MediaPlayerThread(file_paths)\n",
    "media_player_thread.start()\n",
    "\n",
    "# Adding a short delay to allow the media player to initialize\n",
    "time.sleep(1)\n",
    "\n",
    "print('is_playing:', media_player_thread.player.is_playing())\n",
    "\n",
    "# Now you can control playback from other cells\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875aebaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_player_thread.next_song()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17709773",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_player_thread.previous_song()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03217963",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_player_thread.pause()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f509fb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_player_thread.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9902d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_player_thread.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7031efc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_player_thread.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9711e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_player_thread.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141d122a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
